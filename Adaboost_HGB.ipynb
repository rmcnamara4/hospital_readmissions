{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a857997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec7bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "data = pd.read_csv('./diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6be29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y \n",
    "X = data.drop('readmitted', axis = 1)\n",
    "y = data['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d6a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make classification binary \n",
    "y = y.replace('>30', 'YES')\n",
    "y = y.replace('<30', 'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3ccd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we don't need \n",
    "columns_to_drop = ['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty', 'examide', 'citoglipton']\n",
    "\n",
    "X = X.drop(columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e1d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "X['diag_1'] = X['diag_1'].astype(str).apply(lambda x: re.sub( r'\\.*$', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0468cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         250.83\n",
       "1            276\n",
       "2            648\n",
       "3              8\n",
       "4            197\n",
       "           ...  \n",
       "101761    250.13\n",
       "101762       560\n",
       "101763        38\n",
       "101764       996\n",
       "101765       530\n",
       "Name: diag_1, Length: 101766, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['diag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841981ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into dev and test set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, stratify = y_dev, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0018d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values for categorical variables \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "imp = SimpleImputer(missing_values = '?', strategy = 'most_frequent')\n",
    "\n",
    "X_train = pd.DataFrame(imp.fit_transform(X_train), columns = feature_names)\n",
    "X_val = pd.DataFrame(imp.transform(X_val), columns = feature_names)\n",
    "X_test = pd.DataFrame(imp.transform(X_test), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1ea295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode target variable \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "y_train = pd.Series(le.fit_transform(y_train))\n",
    "y_val = pd.Series(le.transform(y_val))\n",
    "y_test = pd.Series(le.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "203b48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline for preprocessing \n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from category_encoders import TargetEncoder \n",
    "\n",
    "te_features = ['race', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "              'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', \n",
    "              'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \n",
    "              'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', \n",
    "              'acarbose', 'miglitol', 'troglitazone', 'tolazamide', \n",
    "              'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', \n",
    "              'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed']\n",
    "\n",
    "oe_features = ['age']\n",
    "\n",
    "other_features = []\n",
    "for i in feature_names: \n",
    "    if i not in (te_features + oe_features): \n",
    "        other_features.append(i)\n",
    "\n",
    "preprocess = make_column_transformer((OrdinalEncoder(), oe_features), \n",
    "                                    (TargetEncoder(), te_features), remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58531e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encode variables \n",
    "X_train = preprocess.fit_transform(X_train, y_train)\n",
    "X_val = preprocess.transform(X_val)\n",
    "X_test = preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dede0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data \n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.fit_transform(X_val)\n",
    "X_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6567dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train, columns = oe_features + te_features + other_features).to_csv('X_train.csv', index = False)\n",
    "pd.DataFrame(X_val, columns = oe_features + te_features + other_features).to_csv('X_val.csv', index = False)\n",
    "pd.DataFrame(X_test, columns = oe_features + te_features + other_features).to_csv('X_test.csv', index = False)\n",
    "\n",
    "y_train.to_csv('y_train.csv', index = False)\n",
    "y_val.to_csv('y_val.csv', index = False)\n",
    "y_test.to_csv('y_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d8626",
   "metadata": {},
   "source": [
    "Now do it again to make dev and test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36990e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "# impute missing values for categorical variables \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "imp = SimpleImputer(missing_values = '?', strategy = 'most_frequent')\n",
    "\n",
    "X_dev = pd.DataFrame(imp.fit_transform(X_dev), columns = feature_names)\n",
    "X_test = pd.DataFrame(imp.transform(X_test), columns = feature_names)\n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "y_dev = pd.Series(le.fit_transform(y_dev))\n",
    "y_test = pd.Series(le.transform(y_test))\n",
    "\n",
    "te_features = ['race', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "              'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', \n",
    "              'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \n",
    "              'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', \n",
    "              'acarbose', 'miglitol', 'troglitazone', 'tolazamide', \n",
    "              'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', \n",
    "              'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed']\n",
    "\n",
    "oe_features = ['age']\n",
    "\n",
    "preprocess = make_column_transformer((OrdinalEncoder(), oe_features), \n",
    "                                    (TargetEncoder(), te_features), remainder = 'passthrough')\n",
    "\n",
    "X_dev = preprocess.fit_transform(X_dev, y_dev)\n",
    "X_test = preprocess.transform(X_test)\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_dev = ss.fit_transform(X_dev)\n",
    "X_test = ss.fit_transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_dev, columns = oe_features + te_features + other_features).to_csv('X_dev_final.csv', index = False)\n",
    "pd.DataFrame(X_test, columns = oe_features + te_features + other_features).to_csv('X_test_final.csv', index = False)\n",
    "y_dev.to_csv('y_dev_final.csv', index = False)\n",
    "y_test.to_csv('y_test_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8947e61",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be97bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "abc = AdaBoostClassifier(random_state=42)\n",
    "abc_model1 = abc.fit(X_train, y_train)\n",
    "y_pred = abc_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b56bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Adaboost model accuracy score 0.6384494448265697\n",
      "Base Adaboost model F1 score 0.5744028685443293\n",
      "Base Adaboost model F1 Macro score 0.6300719983922484\n"
     ]
    }
   ],
   "source": [
    "print('Base Adaboost model accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('Base Adaboost model F1 score', f1_score(y_test, y_pred))\n",
    "print('Base Adaboost model F1 Macro score', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7be950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adaboost with SVC base estimator\n",
    "# from sklearn.svm import SVC\n",
    "# svc = SVC(probability=True, kernel='linear')\n",
    "# abc_svc = AdaBoostClassifier(base_estimator=svc, random_state=42)\n",
    "\n",
    "# abc_model2 = abc_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907ff719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = abc_model2.predict(X_test)\n",
    "# print('Adaboost with SVC base estimator accuracy score', accuracy_score(y_test, y_pred))\n",
    "# print('Adaboost with SVC base estimator F1 score', f1_score(y_test, y_pred))\n",
    "# print('Adaboost with SVC base estimator F1 Macro score', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a8527b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.653765 using {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.612748 (0.004867) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.621874 (0.004812) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.634133 (0.004820) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.634620 (0.004515) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.643947 (0.004530) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.652005 (0.004642) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.649646 (0.004745) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.652005 (0.004408) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.653765 (0.004331) with: {'learning_rate': 1.0, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# grid search hyperparameter tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "abc_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [50, 100, 500]\n",
    "grid['learning_rate'] = [0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=abc_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "\n",
    "grid_result = grid_search.fit(X_dev, y_dev)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4637539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr, best_n_est = grid_result.best_params_['learning_rate'], grid_result.best_params_['n_estimators']\n",
    "abc_model = AdaBoostClassifier(n_estimators=best_n_est, learning_rate=best_lr, random_state=42)\n",
    "\n",
    "abc_model.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae696397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Adaboost model accuracy score 0.6416429203105041\n",
      "Tuned Adaboost model F1 score 0.5806599977003565\n",
      "Tuned Adaboost model F1 Macro score 0.6339003857421746\n"
     ]
    }
   ],
   "source": [
    "y_pred = abc_model.predict(X_test)\n",
    "print('Tuned Adaboost model accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('Tuned Adaboost model F1 score', f1_score(y_test, y_pred))\n",
    "print('Tuned Adaboost model F1 Macro score', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5190d",
   "metadata": {},
   "source": [
    "### HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e76d41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_model1 = hgb.fit(X_train, y_train)\n",
    "y_pred = hgb_model1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e79fb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base HistGradientBoosting model accuracy score 0.6442959614817726\n",
      "Base HistGradientBoosting model F1 score 0.6035049288061336\n",
      "Base HistGradientBoosting model F1 Macro score 0.6404908820794745\n"
     ]
    }
   ],
   "source": [
    "print('Base HistGradientBoosting model accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('Base HistGradientBoosting model F1 score', f1_score(y_test, y_pred))\n",
    "print('Base HistGradientBoosting model F1 Macro score', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b41f21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.657594 using {'learning_rate': 0.05, 'max_depth': 25, 'max_iter': 500}\n",
      "0.643501 (0.005242) with: {'learning_rate': 0.01, 'max_depth': 25, 'max_iter': 100}\n",
      "0.656259 (0.005116) with: {'learning_rate': 0.01, 'max_depth': 25, 'max_iter': 500}\n",
      "0.657200 (0.004557) with: {'learning_rate': 0.01, 'max_depth': 25, 'max_iter': 1000}\n",
      "0.643501 (0.005242) with: {'learning_rate': 0.01, 'max_depth': 50, 'max_iter': 100}\n",
      "0.656259 (0.005116) with: {'learning_rate': 0.01, 'max_depth': 50, 'max_iter': 500}\n",
      "0.657200 (0.004557) with: {'learning_rate': 0.01, 'max_depth': 50, 'max_iter': 1000}\n",
      "0.643501 (0.005242) with: {'learning_rate': 0.01, 'max_depth': 75, 'max_iter': 100}\n",
      "0.656259 (0.005116) with: {'learning_rate': 0.01, 'max_depth': 75, 'max_iter': 500}\n",
      "0.657200 (0.004557) with: {'learning_rate': 0.01, 'max_depth': 75, 'max_iter': 1000}\n",
      "0.656496 (0.004129) with: {'learning_rate': 0.05, 'max_depth': 25, 'max_iter': 100}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 25, 'max_iter': 500}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 25, 'max_iter': 1000}\n",
      "0.656496 (0.004129) with: {'learning_rate': 0.05, 'max_depth': 50, 'max_iter': 100}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 50, 'max_iter': 500}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 50, 'max_iter': 1000}\n",
      "0.656496 (0.004129) with: {'learning_rate': 0.05, 'max_depth': 75, 'max_iter': 100}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 75, 'max_iter': 500}\n",
      "0.657594 (0.003803) with: {'learning_rate': 0.05, 'max_depth': 75, 'max_iter': 1000}\n",
      "0.656943 (0.004615) with: {'learning_rate': 0.1, 'max_depth': 25, 'max_iter': 100}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 25, 'max_iter': 500}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 25, 'max_iter': 1000}\n",
      "0.656943 (0.004615) with: {'learning_rate': 0.1, 'max_depth': 50, 'max_iter': 100}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 50, 'max_iter': 500}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 50, 'max_iter': 1000}\n",
      "0.656943 (0.004615) with: {'learning_rate': 0.1, 'max_depth': 75, 'max_iter': 100}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 75, 'max_iter': 500}\n",
      "0.656865 (0.004658) with: {'learning_rate': 0.1, 'max_depth': 75, 'max_iter': 1000}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 25, 'max_iter': 100}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 25, 'max_iter': 500}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 25, 'max_iter': 1000}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 50, 'max_iter': 100}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 50, 'max_iter': 500}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 50, 'max_iter': 1000}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 75, 'max_iter': 100}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 75, 'max_iter': 500}\n",
      "0.643222 (0.004534) with: {'learning_rate': 1, 'max_depth': 75, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "# grid search hyperparameter tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "grid = {\n",
    "    \"max_depth\": [25, 50, 75],\n",
    "    \"max_iter\": [100, 500, 1000],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 1],\n",
    "}\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=hgb_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "\n",
    "grid_result = grid_search.fit(X_dev, y_dev)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8350d04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier(learning_rate=0.05, max_depth=25, max_iter=500,\n",
       "                               random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(learning_rate=0.05, max_depth=25, max_iter=500,\n",
       "                               random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier(learning_rate=0.05, max_depth=25, max_iter=500,\n",
       "                               random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr, best_max_depth, best_max_iter = grid_result.best_params_['learning_rate'], grid_result.best_params_['max_depth'], grid_result.best_params_['max_iter']\n",
    "hgb_model = HistGradientBoostingClassifier(max_depth=best_max_depth, learning_rate=best_lr, max_iter=best_max_iter, random_state=42)\n",
    "\n",
    "hgb_model.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ea390d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Adaboost model accuracy score 0.6469490026530411\n",
      "Tuned Adaboost model F1 score 0.604599977990536\n",
      "Tuned Adaboost model F1 Macro score 0.6428520436682067\n"
     ]
    }
   ],
   "source": [
    "y_pred = hgb_model.predict(X_test)\n",
    "print('Tuned Adaboost model accuracy score', accuracy_score(y_test, y_pred))\n",
    "print('Tuned Adaboost model F1 score', f1_score(y_test, y_pred))\n",
    "print('Tuned Adaboost model F1 Macro score', f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c385d26da54d8afa207aba33a323dc8adec771519c96e85eaf7cd891c73a9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "002ec40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be7862a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_val = pd.read_csv('y_val.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "758291d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.192159</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>0.363742</td>\n",
       "      <td>-3.748811</td>\n",
       "      <td>-0.185611</td>\n",
       "      <td>0.778112</td>\n",
       "      <td>0.853356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926034</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>1.541554</td>\n",
       "      <td>0.098788</td>\n",
       "      <td>0.971395</td>\n",
       "      <td>0.607126</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>0.292932</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.818312</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.156657</td>\n",
       "      <td>0.928516</td>\n",
       "      <td>0.853356</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.468064</td>\n",
       "      <td>1.315411</td>\n",
       "      <td>-0.784384</td>\n",
       "      <td>0.117296</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>4.288400</td>\n",
       "      <td>0.292932</td>\n",
       "      <td>-1.251018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.060145</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>-1.080001</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>1.279848</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>-0.185611</td>\n",
       "      <td>0.078171</td>\n",
       "      <td>-0.562232</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.133128</td>\n",
       "      <td>-2.131687</td>\n",
       "      <td>-0.784384</td>\n",
       "      <td>0.117296</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>0.909317</td>\n",
       "      <td>0.292932</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>0.520970</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.409514</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>-0.310442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926034</td>\n",
       "      <td>-1.830156</td>\n",
       "      <td>0.536745</td>\n",
       "      <td>-0.408138</td>\n",
       "      <td>1.556654</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.686298</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.679034</td>\n",
       "      <td>-0.060426</td>\n",
       "      <td>0.029327</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.133128</td>\n",
       "      <td>0.504329</td>\n",
       "      <td>-0.784384</td>\n",
       "      <td>-0.005161</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>0.909317</td>\n",
       "      <td>0.292932</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65124</th>\n",
       "      <td>65124</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>-0.613228</td>\n",
       "      <td>-1.080001</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>-6.026151</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>-0.714418</td>\n",
       "      <td>-0.947060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>1.206617</td>\n",
       "      <td>0.301558</td>\n",
       "      <td>-0.784384</td>\n",
       "      <td>0.484669</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>-1.768267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65125</th>\n",
       "      <td>65125</td>\n",
       "      <td>1.192159</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.640928</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926034</td>\n",
       "      <td>-1.830156</td>\n",
       "      <td>1.206617</td>\n",
       "      <td>0.301558</td>\n",
       "      <td>0.971395</td>\n",
       "      <td>-0.494991</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65126</th>\n",
       "      <td>65126</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>-1.080001</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>-0.540645</td>\n",
       "      <td>1.947502</td>\n",
       "      <td>1.260127</td>\n",
       "      <td>0.530070</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>1.206617</td>\n",
       "      <td>-0.762987</td>\n",
       "      <td>-0.199124</td>\n",
       "      <td>-0.127619</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65127</th>\n",
       "      <td>65127</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>-1.080001</td>\n",
       "      <td>0.325692</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>-0.208768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.468064</td>\n",
       "      <td>1.366103</td>\n",
       "      <td>-0.199124</td>\n",
       "      <td>0.729584</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>-0.217044</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65128</th>\n",
       "      <td>65128</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.925939</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>-0.538581</td>\n",
       "      <td>0.733692</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079875</td>\n",
       "      <td>0.546401</td>\n",
       "      <td>-0.133128</td>\n",
       "      <td>0.605714</td>\n",
       "      <td>2.727173</td>\n",
       "      <td>-0.005161</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>0.909317</td>\n",
       "      <td>-0.501602</td>\n",
       "      <td>0.817977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65129 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0               0  1.192159  0.375362  0.925939  0.325692  0.363742 -3.748811   \n",
       "1               1  1.818312  0.375362  0.925939  0.104645 -0.130120  0.617627   \n",
       "2               2 -0.060145  0.375362 -1.080001  0.325692  1.279848  0.617627   \n",
       "3               3  0.566007  0.375362  0.925939  0.325692  0.520970  0.617627   \n",
       "4               4 -0.686298  0.375362  0.925939  0.325692 -0.130120  0.617627   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "65124       65124  0.566007 -0.613228 -1.080001  0.325692 -6.026151  0.617627   \n",
       "65125       65125  1.192159  0.375362  0.925939  0.325692 -0.130120  0.617627   \n",
       "65126       65126  0.566007  0.375362 -1.080001  0.104645 -0.130120 -0.540645   \n",
       "65127       65127  0.566007  0.375362 -1.080001  0.325692 -0.130120  0.617627   \n",
       "65128       65128  0.566007  0.375362  0.925939  0.104645 -0.130120  0.617627   \n",
       "\n",
       "              6         7         8  ...        32        33        34  \\\n",
       "0     -0.185611  0.778112  0.853356  ... -0.926034  0.546401  1.541554   \n",
       "1      0.156657  0.928516  0.853356  ...  1.079875  0.546401 -0.468064   \n",
       "2     -0.185611  0.078171 -0.562232  ...  1.079875  0.546401 -0.133128   \n",
       "3      0.409514  0.126600 -0.310442  ... -0.926034 -1.830156  0.536745   \n",
       "4      0.679034 -0.060426  0.029327  ...  1.079875  0.546401 -0.133128   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "65124  0.136435 -0.714418 -0.947060  ...  1.079875  0.546401  1.206617   \n",
       "65125  0.640928  0.126600 -0.498034  ... -0.926034 -1.830156  1.206617   \n",
       "65126  1.947502  1.260127  0.530070  ...  1.079875  0.546401  1.206617   \n",
       "65127  0.136435  0.126600 -0.208768  ...  1.079875  0.546401 -0.468064   \n",
       "65128 -0.538581  0.733692  1.354150  ...  1.079875  0.546401 -0.133128   \n",
       "\n",
       "             35        36        37        38        39        40        41  \n",
       "0      0.098788  0.971395  0.607126 -0.287584 -0.217044  0.292932  0.817977  \n",
       "1      1.315411 -0.784384  0.117296 -0.287584  4.288400  0.292932 -1.251018  \n",
       "2     -2.131687 -0.784384  0.117296 -0.287584  0.909317  0.292932  0.817977  \n",
       "3     -0.408138  1.556654  0.852042 -0.287584 -0.217044 -0.501602  0.817977  \n",
       "4      0.504329 -0.784384 -0.005161 -0.287584  0.909317  0.292932  0.817977  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "65124  0.301558 -0.784384  0.484669 -0.287584 -0.217044 -0.501602 -1.768267  \n",
       "65125  0.301558  0.971395 -0.494991 -0.287584 -0.217044 -0.501602  0.817977  \n",
       "65126 -0.762987 -0.199124 -0.127619 -0.287584 -0.217044 -0.501602  0.817977  \n",
       "65127  1.366103 -0.199124  0.729584 -0.287584 -0.217044 -0.501602  0.817977  \n",
       "65128  0.605714  2.727173 -0.005161 -0.287584  0.909317 -0.501602  0.817977  \n",
       "\n",
       "[65129 rows x 43 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "842535bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.4148949016937844\n",
      "Validation macro recall: 0.4148949016937844\n",
      "Validaton macro precision: 0.5196633902257886\n",
      "Validation macro f1: 0.3968965057276766\n",
      "\n",
      "Test balanced accuracy: 0.4126418041880078\n",
      "Test macro recall: 0.4126418041880078\n",
      "Test macro precision: 0.5368314767178973\n",
      "Test macro f1: 0.39406336079829324\n"
     ]
    }
   ],
   "source": [
    "# create RandomForest model with default parameters for baseline performance \n",
    "# import functions \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, recall_score, precision_score \n",
    "\n",
    "# initialize RandomForest model \n",
    "rfc_baseline = RandomForestClassifier()\n",
    "\n",
    "# fit model to training data \n",
    "rfc_baseline.fit(X_train, y_train)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_val = rfc_baseline.predict(X_val)\n",
    "y_pred_test = rfc_baseline.predict(X_test)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_val, y_pred_val))\n",
    "print('Validation macro recall:', recall_score(y_val, y_pred_val, average = 'macro'))\n",
    "print('Validaton macro precision:', precision_score(y_val, y_pred_val, average = 'macro'))\n",
    "print('Validation macro f1:', f1_score(y_val, y_pred_val, average = 'macro'))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Test balanced accuracy:', balanced_accuracy_score(y_test, y_pred_test))\n",
    "print('Test macro recall:', recall_score(y_test, y_pred_test, average = 'macro'))\n",
    "print('Test macro precision:', precision_score(y_test, y_pred_test, average = 'macro'))\n",
    "print('Test macro f1:', f1_score(y_test, y_pred_test, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62ba99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 10\n",
      "Confirmed: \t6\n",
      "Tentative: \t1\n",
      "Rejected: \t68\n",
      "Iteration: \t9 / 10\n",
      "Confirmed: \t6\n",
      "Tentative: \t1\n",
      "Rejected: \t68\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t10 / 10\n",
      "Confirmed: \t6\n",
      "Tentative: \t0\n",
      "Rejected: \t68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(n_estimators=37,\n",
       "                                          random_state=RandomState(MT19937) at 0x104E41440),\n",
       "         max_iter=10, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x104E41440, verbose=2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "feat_selector = BorutaPy(\n",
    "    estimator = RandomForestClassifier(), \n",
    "    n_estimators = 'auto', \n",
    "    max_iter = 10, \n",
    "    verbose = 2)\n",
    "\n",
    "feat_selector.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c61f387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Feature Selection-----\n",
      "Does not pass the test: age - Ranking: 8\n",
      "Does not pass the test: time_in_hospital - Ranking: 5\n",
      "Does not pass the test: num_lab_procedures - Ranking: 2\n",
      "Does not pass the test: num_procedures - Ranking: 10\n",
      "Does not pass the test: num_medications - Ranking: 4\n",
      "Does not pass the test: number_outpatient - Ranking: 11\n",
      "Does not pass the test: number_emergency - Ranking: 16\n",
      "Does not pass the test: number_inpatient - Ranking: 3\n",
      "Does not pass the test: number_diagnoses - Ranking: 9\n",
      "Does not pass the test: race_1 - Ranking: 19\n",
      "Does not pass the test: gender_1 - Ranking: 23\n",
      "Does not pass the test: admission_type_id_1 - Ranking: 14\n",
      "Does not pass the test: discharge_disposition_id_1 - Ranking: 6\n",
      "Does not pass the test: admission_source_id_1 - Ranking: 15\n",
      "Passes the test: diag_1_1 - Ranking: 1\n",
      "Passes the test: diag_2_1 - Ranking: 1\n",
      "Passes the test: diag_3_1 - Ranking: 1\n",
      "Does not pass the test: max_glu_serum_1 - Ranking: 37\n",
      "Does not pass the test: A1Cresult_1 - Ranking: 21\n",
      "Does not pass the test: metformin_1 - Ranking: 25\n",
      "Does not pass the test: repaglinide_1 - Ranking: 43\n",
      "Does not pass the test: nateglinide_1 - Ranking: 45\n",
      "Does not pass the test: chlorpropamide_1 - Ranking: 51\n",
      "Does not pass the test: glimepiride_1 - Ranking: 41\n",
      "Does not pass the test: acetohexamide_1 - Ranking: 66\n",
      "Does not pass the test: glipizide_1 - Ranking: 28\n",
      "Does not pass the test: glyburide_1 - Ranking: 31\n",
      "Does not pass the test: tolbutamide_1 - Ranking: 60\n",
      "Does not pass the test: pioglitazone_1 - Ranking: 36\n",
      "Does not pass the test: rosiglitazone_1 - Ranking: 39\n",
      "Does not pass the test: acarbose_1 - Ranking: 49\n",
      "Does not pass the test: miglitol_1 - Ranking: 53\n",
      "Does not pass the test: troglitazone_1 - Ranking: 62\n",
      "Does not pass the test: tolazamide_1 - Ranking: 55\n",
      "Does not pass the test: insulin_1 - Ranking: 17\n",
      "Does not pass the test: glyburide-metformin_1 - Ranking: 48\n",
      "Does not pass the test: glipizide-metformin_1 - Ranking: 57\n",
      "Does not pass the test: glimepiride-pioglitazone_1 - Ranking: 69\n",
      "Does not pass the test: metformin-rosiglitazone_1 - Ranking: 64\n",
      "Does not pass the test: metformin-pioglitazone_1 - Ranking: 69\n",
      "Does not pass the test: change_1 - Ranking: 31\n",
      "Does not pass the test: diabetesMed_1 - Ranking: 33\n",
      "Does not pass the test: race_2 - Ranking: 20\n",
      "Does not pass the test: gender_2 - Ranking: 24\n",
      "Does not pass the test: admission_type_id_2 - Ranking: 12\n",
      "Does not pass the test: discharge_disposition_id_2 - Ranking: 7\n",
      "Does not pass the test: admission_source_id_2 - Ranking: 13\n",
      "Passes the test: diag_1_2 - Ranking: 1\n",
      "Passes the test: diag_2_2 - Ranking: 1\n",
      "Passes the test: diag_3_2 - Ranking: 1\n",
      "Does not pass the test: max_glu_serum_2 - Ranking: 38\n",
      "Does not pass the test: A1Cresult_2 - Ranking: 22\n",
      "Does not pass the test: metformin_2 - Ranking: 26\n",
      "Does not pass the test: repaglinide_2 - Ranking: 44\n",
      "Does not pass the test: nateglinide_2 - Ranking: 47\n",
      "Does not pass the test: chlorpropamide_2 - Ranking: 52\n",
      "Does not pass the test: glimepiride_2 - Ranking: 42\n",
      "Does not pass the test: acetohexamide_2 - Ranking: 63\n",
      "Does not pass the test: glipizide_2 - Ranking: 27\n",
      "Does not pass the test: glyburide_2 - Ranking: 29\n",
      "Does not pass the test: tolbutamide_2 - Ranking: 59\n",
      "Does not pass the test: pioglitazone_2 - Ranking: 35\n",
      "Does not pass the test: rosiglitazone_2 - Ranking: 39\n",
      "Does not pass the test: acarbose_2 - Ranking: 49\n",
      "Does not pass the test: miglitol_2 - Ranking: 55\n",
      "Does not pass the test: troglitazone_2 - Ranking: 61\n",
      "Does not pass the test: tolazamide_2 - Ranking: 53\n",
      "Does not pass the test: insulin_2 - Ranking: 18\n",
      "Does not pass the test: glyburide-metformin_2 - Ranking: 46\n",
      "Does not pass the test: glipizide-metformin_2 - Ranking: 58\n",
      "Does not pass the test: glimepiride-pioglitazone_2 - Ranking: 67\n",
      "Does not pass the test: metformin-rosiglitazone_2 - Ranking: 65\n",
      "Does not pass the test: metformin-pioglitazone_2 - Ranking: 69\n",
      "Does not pass the test: change_2 - Ranking: 31\n",
      "Does not pass the test: diabetesMed_2 - Ranking: 33\n"
     ]
    }
   ],
   "source": [
    "print('-----Feature Selection-----') \n",
    "for i in range(len(feat_selector.support_)): \n",
    "    if feat_selector.support_[i]:\n",
    "        print('Passes the test:', X_train.columns[i], \n",
    "             '- Ranking:', feat_selector.ranking_[i])\n",
    "    else: \n",
    "        print('Does not pass the test:', X_train.columns[i], '- Ranking:', feat_selector.ranking_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dd22788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = []\n",
    "for i, rank in enumerate(feat_selector.ranking_): \n",
    "    if rank < 15: \n",
    "        cols_to_keep.append(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d459c40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.4110314259156446\n",
      "Validation macro recall: 0.4110314259156446\n",
      "Validaton macro precision: 0.4767918798490856\n",
      "Validation macro f1: 0.3959792134734536\n"
     ]
    }
   ],
   "source": [
    "X_train_filtered = X_train[cols_to_keep]\n",
    "X_val_filtered = X_val[cols_to_keep]\n",
    "\n",
    "# initialize RandomForest model \n",
    "rfc_baseline = RandomForestClassifier()\n",
    "\n",
    "# fit model to training data \n",
    "rfc_baseline.fit(X_train_filtered, y_train)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_val = rfc_baseline.predict(X_val_filtered)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_val, y_pred_val))\n",
    "print('Validation macro recall:', recall_score(y_val, y_pred_val, average = 'macro'))\n",
    "print('Validaton macro precision:', precision_score(y_val, y_pred_val, average = 'macro'))\n",
    "print('Validation macro f1:', f1_score(y_val, y_pred_val, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "221dcfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->1->2->3->4->5->6->7->8->9->10->11->12->13->14->15->16->17->18->19->20->21->22->23->24->25->26->27->28->29->30->31->32->33->34->35->36->37->38->39->40->41->42->43->44->45->46->47->48->49->50->51->52->53->54->55->56->57->58->59->60->61->62->63->64->65->66->67->68->69->70->71->72->73->74->75->76->77->78->79->80->81->82->83->84->85->86->87->88->89->90->91->92->93->94->95->96->97->98->99->100->101->102->103->104->105->106->107->108->109->110->111->112->113->114->115->116->117->118->119->120->121->122->123->124->125->126->127->128->129->130->131->132->133->134->135->136->137->138->139->140->141->142->143->144->145->146->147->148->149->150->151->152->153->154->155->156->157->158->159->160->161->162->163->164->165->166->167->168->169->170->171->172->173->174->175->176->177->178->179->180->181->182->183->184->185->186->187->188->189->190->191->192->193->194->195->196->197->198->199->"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "val_scores = []\n",
    "params = []\n",
    "for i in range(200): \n",
    "    \n",
    "    print(i, end = '->')\n",
    "    \n",
    "    p = {\n",
    "        'max_depth': random.randint(3, 25), \n",
    "        'max_features': random.uniform(0, 1), \n",
    "        'max_samples': random.uniform(0, 1),\n",
    "        'n_estimators': random.randint(10, 150), \n",
    "        'ccp_alpha': random.uniform(0, 0.05)\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators = p['n_estimators'], \n",
    "                                max_depth = p['max_depth'], \n",
    "                                max_features = p['max_features'], \n",
    "                                max_samples = p['max_samples'], \n",
    "                                ccp_alpha = p['ccp_alpha'])\n",
    "    \n",
    "    model.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val_filtered)\n",
    "    \n",
    "    params.append(p)\n",
    "    val_scores.append(f1_score(y_val, y_pred_val, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e7ec461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 21,\n",
       " 'max_features': 0.8744250198936229,\n",
       " 'max_samples': 0.017926043764959432,\n",
       " 'n_estimators': 84,\n",
       " 'ccp_alpha': 0.00014223122907068287}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[np.argmax(val_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89cb3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [15, 18, 21, 24], \n",
    "    'max_features': [0.6, 0.65, 0.7]\n",
    "}\n",
    "\n",
    "search_grid = ParameterGrid(param_grid) \n",
    "\n",
    "val_scores_new = []\n",
    "for x in search_grid: \n",
    "    \n",
    "    model = RandomForestClassifier(max_depth = x['max_depth'], max_features = x['max_features'])\n",
    "    \n",
    "    model.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val_filtered)\n",
    "    \n",
    "    val_scores_new.append(f1_score(y_val, y_pred_val, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2ce64e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38632224967918494"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "437c9147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.7, 'max_depth': 21}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_grid[np.argmax(val_scores_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d94eeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = pd.read_csv('X_dev_encoded_final.csv')\n",
    "X_test_final = pd.read_csv('X_test_encoded_final.csv')\n",
    "\n",
    "X_dev_filtered = X_dev[cols_to_keep]\n",
    "X_test_final_filtered = X_test_final[cols_to_keep]\n",
    "\n",
    "y_dev = pd.read_csv('y_dev_encoded_final.csv')\n",
    "y_test_final = pd.read_csv('y_test_encoded_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "371b545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.40799575740560473\n",
      "Validation macro recall: 0.40799575740560473\n",
      "Validaton macro precision: 0.47407378111887083\n",
      "Validation macro f1: 0.39582281481538445\n"
     ]
    }
   ],
   "source": [
    "# initialize RandomForest model \n",
    "rfc_final = RandomForestClassifier(max_features = 0.7, max_depth = 21)\n",
    "\n",
    "# fit model to training data \n",
    "rfc_final.fit(X_dev_filtered, y_dev)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_test = rfc_final.predict(X_test_final_filtered)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_test_final, y_pred_test))\n",
    "print('Validation macro recall:', recall_score(y_test_final, y_pred_test, average = 'macro'))\n",
    "print('Validaton macro precision:', precision_score(y_test_final, y_pred_test, average = 'macro'))\n",
    "print('Validation macro f1:', f1_score(y_test_final, y_pred_test, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d7ca1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'time_in_hospital',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'num_medications',\n",
       " 'number_outpatient',\n",
       " 'number_inpatient',\n",
       " 'number_diagnoses',\n",
       " 'admission_type_id_1',\n",
       " 'discharge_disposition_id_1',\n",
       " 'diag_1_1',\n",
       " 'diag_2_1',\n",
       " 'diag_3_1',\n",
       " 'admission_type_id_2',\n",
       " 'discharge_disposition_id_2',\n",
       " 'admission_source_id_2',\n",
       " 'diag_1_2',\n",
       " 'diag_2_2',\n",
       " 'diag_3_2']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfef21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

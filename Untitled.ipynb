{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "436b5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "010d9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_val = pd.read_csv('y_val.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec5d27ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.6340501832974648\n",
      "Validation recall: 0.5542377398720683\n",
      "Validaton precision: 0.6234447609054115\n",
      "Validation f1: 0.5868077601410935\n",
      "\n",
      "Test balanced accuracy: 0.6349302757484032\n",
      "Test recall: 0.5560174821447607\n",
      "Test precision: 0.6242221158449018\n",
      "Test f1: 0.5881490669222529\n"
     ]
    }
   ],
   "source": [
    "# create RandomForest model with default parameters for baseline performance \n",
    "# import functions \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, recall_score, precision_score \n",
    "\n",
    "# initialize RandomForest model \n",
    "rfc_baseline = RandomForestClassifier()\n",
    "\n",
    "# fit model to training data \n",
    "rfc_baseline.fit(X_train, y_train)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_val = rfc_baseline.predict(X_val)\n",
    "y_pred_test = rfc_baseline.predict(X_test)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_val, y_pred_val))\n",
    "print('Validation recall:', recall_score(y_val, y_pred_val))\n",
    "print('Validaton precision:', precision_score(y_val, y_pred_val))\n",
    "print('Validation f1:', f1_score(y_val, y_pred_val))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Test balanced accuracy:', balanced_accuracy_score(y_test, y_pred_test))\n",
    "print('Test recall:', recall_score(y_test, y_pred_test))\n",
    "print('Test precision:', precision_score(y_test, y_pred_test))\n",
    "print('Test f1:', f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "660033c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t42\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t4\n",
      "Rejected: \t38\n",
      "Iteration: \t9 / 10\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t38\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t10 / 10\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(n_estimators=28,\n",
       "                                          random_state=RandomState(MT19937) at 0x104E41440),\n",
       "         max_iter=10, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x104E41440, verbose=2)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "feat_selector = BorutaPy(\n",
    "    estimator = RandomForestClassifier(), \n",
    "    n_estimators = 'auto', \n",
    "    max_iter = 10, \n",
    "    verbose = 2)\n",
    "\n",
    "feat_selector.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "503e1b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Feature Selection-----\n",
      "Does not pass the test: 0 - Ranking: 7\n",
      "Does not pass the test: 1 - Ranking: 15\n",
      "Does not pass the test: 2 - Ranking: 17\n",
      "Does not pass the test: 3 - Ranking: 11\n",
      "Does not pass the test: 4 - Ranking: 5\n",
      "Does not pass the test: 5 - Ranking: 10\n",
      "Passes the test: 6 - Ranking: 1\n",
      "Passes the test: 7 - Ranking: 1\n",
      "Passes the test: 8 - Ranking: 1\n",
      "Does not pass the test: 9 - Ranking: 24\n",
      "Does not pass the test: 10 - Ranking: 16\n",
      "Does not pass the test: 11 - Ranking: 18\n",
      "Does not pass the test: 12 - Ranking: 27\n",
      "Does not pass the test: 13 - Ranking: 29\n",
      "Does not pass the test: 14 - Ranking: 31\n",
      "Does not pass the test: 15 - Ranking: 26\n",
      "Does not pass the test: 16 - Ranking: 39\n",
      "Does not pass the test: 17 - Ranking: 19\n",
      "Does not pass the test: 18 - Ranking: 21\n",
      "Does not pass the test: 19 - Ranking: 34\n",
      "Does not pass the test: 20 - Ranking: 23\n",
      "Does not pass the test: 21 - Ranking: 25\n",
      "Does not pass the test: 22 - Ranking: 30\n",
      "Does not pass the test: 23 - Ranking: 33\n",
      "Does not pass the test: 24 - Ranking: 37\n",
      "Does not pass the test: 25 - Ranking: 32\n",
      "Does not pass the test: 26 - Ranking: 12\n",
      "Does not pass the test: 27 - Ranking: 28\n",
      "Does not pass the test: 28 - Ranking: 35\n",
      "Does not pass the test: 29 - Ranking: 39\n",
      "Does not pass the test: 30 - Ranking: 36\n",
      "Does not pass the test: 31 - Ranking: 39\n",
      "Does not pass the test: 32 - Ranking: 20\n",
      "Does not pass the test: 33 - Ranking: 22\n",
      "Does not pass the test: 34 - Ranking: 6\n",
      "Does not pass the test: 35 - Ranking: 2\n",
      "Does not pass the test: 36 - Ranking: 9\n",
      "Does not pass the test: 37 - Ranking: 4\n",
      "Does not pass the test: 38 - Ranking: 13\n",
      "Does not pass the test: 39 - Ranking: 14\n",
      "Does not pass the test: 40 - Ranking: 3\n",
      "Does not pass the test: 41 - Ranking: 8\n"
     ]
    }
   ],
   "source": [
    "print('-----Feature Selection-----') \n",
    "for i in range(len(feat_selector.support_)): \n",
    "    if feat_selector.support_[i]:\n",
    "        print('Passes the test:', X_train.columns[i], \n",
    "             '- Ranking:', feat_selector.ranking_[i])\n",
    "    else: \n",
    "        print('Does not pass the test:', X_train.columns[i], '- Ranking:', feat_selector.ranking_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20b770bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = []\n",
    "for i, rank in enumerate(feat_selector.ranking_): \n",
    "    if rank < 15: \n",
    "        cols_to_keep.append(X_train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1eaf27b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.6265054278831219\n",
      "Validation recall: 0.5554371002132196\n",
      "Validaton precision: 0.6108749816796131\n",
      "Validation f1: 0.5818384867732255\n"
     ]
    }
   ],
   "source": [
    "X_train_filtered = X_train[cols_to_keep]\n",
    "X_val_filtered = X_val[cols_to_keep]\n",
    "\n",
    "# initialize RandomForest model \n",
    "rfc_baseline = RandomForestClassifier()\n",
    "\n",
    "# fit model to training data \n",
    "rfc_baseline.fit(X_train_filtered, y_train)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_val = rfc_baseline.predict(X_val_filtered)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_val, y_pred_val))\n",
    "print('Validation recall:', recall_score(y_val, y_pred_val))\n",
    "print('Validaton precision:', precision_score(y_val, y_pred_val))\n",
    "print('Validation f1:', f1_score(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fe552e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->1->2->3->4->5->6->7->8->9->10->11->12->13->14->15->16->17->18->19->"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "val_scores = []\n",
    "params = []\n",
    "for i in range(20): \n",
    "    \n",
    "    print(i, end = '->')\n",
    "    \n",
    "    p = {\n",
    "        'max_depth': random.randint(3, 25), \n",
    "        'max_features': random.uniform(0, 1), \n",
    "        'max_samples': random.uniform(0, 1),\n",
    "        'n_estimators': random.randint(10, 150)\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators = p['n_estimators'], \n",
    "                                max_depth = p['max_depth'], \n",
    "                                max_features = p['max_features'], \n",
    "                                max_samples = p['max_samples'])\n",
    "    \n",
    "    model.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val_filtered)\n",
    "    \n",
    "    params.append(p)\n",
    "    val_scores.append(f1_score(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dbed5e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5171397549247713"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "108656af",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [15, 18, 21, 24], \n",
    "    'max_features': [0.6, 0.65, 0.7]\n",
    "}\n",
    "\n",
    "search_grid = ParameterGrid(param_grid) \n",
    "\n",
    "val_scores_new = []\n",
    "for x in search_grid: \n",
    "    \n",
    "    model = RandomForestClassifier(max_depth = x['max_depth'], max_features = x['max_features'])\n",
    "    \n",
    "    model.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val_filtered)\n",
    "    \n",
    "    val_scores_new.append(f1_score(y_val, y_pred_val, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cde9cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38632224967918494"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac319362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.7, 'max_depth': 21}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_grid[np.argmax(val_scores_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2345f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = pd.read_csv('X_dev_encoded_final.csv')\n",
    "X_test_final = pd.read_csv('X_test_encoded_final.csv')\n",
    "\n",
    "X_dev_filtered = X_dev[cols_to_keep]\n",
    "X_test_final_filtered = X_test_final[cols_to_keep]\n",
    "\n",
    "y_dev = pd.read_csv('y_dev_encoded_final.csv')\n",
    "y_test_final = pd.read_csv('y_test_encoded_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a816307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation balanced accuracy: 0.40799575740560473\n",
      "Validation macro recall: 0.40799575740560473\n",
      "Validaton macro precision: 0.47407378111887083\n",
      "Validation macro f1: 0.39582281481538445\n"
     ]
    }
   ],
   "source": [
    "# initialize RandomForest model \n",
    "rfc_final = RandomForestClassifier(max_features = 0.7, max_depth = 21)\n",
    "\n",
    "# fit model to training data \n",
    "rfc_final.fit(X_dev_filtered, y_dev)\n",
    "\n",
    "# predict on validation and test set \n",
    "y_pred_test = rfc_final.predict(X_test_final_filtered)\n",
    "\n",
    "# evaluate on validation and test set \n",
    "print('Validation balanced accuracy:', balanced_accuracy_score(y_test_final, y_pred_test))\n",
    "print('Validation macro recall:', recall_score(y_test_final, y_pred_test, average = 'macro'))\n",
    "print('Validaton macro precision:', precision_score(y_test_final, y_pred_test, average = 'macro'))\n",
    "print('Validation macro f1:', f1_score(y_test_final, y_pred_test, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64213f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'time_in_hospital',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'num_medications',\n",
       " 'number_outpatient',\n",
       " 'number_inpatient',\n",
       " 'number_diagnoses',\n",
       " 'admission_type_id_1',\n",
       " 'discharge_disposition_id_1',\n",
       " 'diag_1_1',\n",
       " 'diag_2_1',\n",
       " 'diag_3_1',\n",
       " 'admission_type_id_2',\n",
       " 'discharge_disposition_id_2',\n",
       " 'admission_source_id_2',\n",
       " 'diag_1_2',\n",
       " 'diag_2_2',\n",
       " 'diag_3_2']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd982b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
